\section{Klasse ImageProcessing}
Das Ziel dieser Klasse ist es, Bilder, die Strichcodes enthalten, so aufzuwerten, dass der Strichode auf jeden Fall von der Bibliothek ZXing erkannt werden kann.

Es sind auch noch einige weitere Funktionen implementiert, die aber im Moment keine Bedeutung für die Aufwertung haben.


\subsection*{Methode isBlurry}
Diese Methode erhält ein 'BufferedImage' und gibt einen Grad an Unschärfe zurück.

Die Unschärfe wird über die Kantenerkennung berechnet, dass heißt, erst werden die Kanten des Bildes berechnet und diese dann in einem schwarz/weiß Bild weiß dargestellt. Danach werden alle nicht schwarzen Pixel addiert und durch die Gesamtanzahl der Pixel dividiert, um eine Zahl(zwischen 0 und 255) für die ungefähre Unschärfe zu erhalten.

Diese Methode ist zwar nicht die genauste, hat aber einen Geschwindigkeitsvorteil gegenüber einer Berechnung über die Fourie-Transformation.


\subsection*{Methode isRotated}
Diese Methode erhält ein 'BufferedImage' und gibt den Rotationswinkel des enthaltenen Strichcodes zurück.

Um den Winkel zu bestimmten, werden vom linken Rand aus starke Helligkeitsunterschiede gesucht und diese gefundenen Punkte werden, von oben nach unten, in einem Array gespeichert. Danach wird überprüft, ob eine Gerade, durch zwei hintereinander liegende Punkte, auch relativ nah an einem dritten, darauf folgenden Punkt vorbei geht. Wenn ja, dann werden weitere Punkte mit dieser Geraden überprüft und so die Anzahl an Punkten auf ihr bestimmt. Die Gerade mit der maximalen Anzahl an Punkten sollte theoretisch dem Anfangs- oder Endstrich des Codes entsprechen.

Dieser Winkelbestimmung ist nicht exakt, aber reicht für Erkennung durch die Bibliothek ZXing vollkommen aus, da Abweichungen von maximal 2$ \circ $ nicht ins Gewicht fallen.
 

\subsection*{Methode brightenBufferedImage\_linear}
Diese Methode erhält ein 'BufferedImage' und eine Aufhellungsrate, die die Stärke der Beleuchtung angibt.Es wird eine hellere/dunklere Variante vom Bild zurück gegeben.

Zum Aufhellen/Verdunkeln wird ein 'RescaleOp'-Filter genutzt, durch den das Bild vom Normalzustand(Helligkeit=1.0) in einen aufgehellten(Helligkeit>1.0) bzw. abgedunkelten(Helligkeit<1.0) Zustand überführt wird.
Dadurch entsteht eine gleichmäßige Aufhellung des ganzen Bildes.

Eine zweite, realistischere, Variante kann mit einem 'LookupTable'-Filter erzeugt werden, durch den das Bild vom Normalzustand durch eine Helligkeitszuweisung ($newPixelColor = ((oldPixelColor/255.0) * 255.0)^2$) zu jedem Pixel aufgehellt wird.
Dadurch entsteht eine realistische Aufhellung, da dunkle Pixel schneller hell werden. Dies entspricht aber nicht dem was wir wollen, da die dunklen Teile für uns am Wichtigsten sind. (Diese Funktion ist trotzdem für mögliche spätere Nutzung als brightenBufferedImage\_quadratic implementiert)


\subsection*{Methode findShades}
Diese Methode erhält ein 'BufferedImage' und gibt das von möglichst allen Schatten befreite Bild in einem anderen 'BufferedImage' zurück.

Die grundsätzliche Idee ist die Kanten von Schatten zu finden und dann entsprechend den eingerahmten Bereich entsprechend aufzuhellen.
Nach der Implementierung ist allerdings klar geworden, dass der 'BackgroundSubtracter' von ImageJ dies bereits sehr gut tut.

Es wurde auch der Canny-Edge-Detector probiert, allerdings werden dabei zu viele mögliche Kanten erkannt. Dadurch erwies er sich als nutzlos.


\subsection*{Methode interpolateBufferedImage}
Diese Methode erhält ein 'BufferedImage' und hellt einen viereckigen Bereich im Bild auf, welcher dann in einem anderen 'BufferedImage' zurückgegeben wird.

Hellt einen Vier-/(Viel-)eckigen Teilbereich auf


\subsection*{Methode rotateBufferedImage}
Diese Methode erhält ein 'BufferedImage' und gibt eine gedrehte Variante davon zurück.

Das Bild wird über eine affine Transformation gedreht und dann der darzustellende Bereich angepasst.


\subsection*{Methode sharpenBufferedImage}
Diese Methode erhält ein 'BufferedImage' und gibt eine schärfere Variante davon zurück.

Für die Schärfung wird die Methode der unscharfen Maskierung benutzt. Dabei wird erst eine unschärfere Variante des Bildes vom Original abgezogen und so eine Maske erzeugt. Diese Maske, multipliziert mit einem Gewichtsfaktor(für die Stärke der Schärfung), wird dann zum Originalbild addiert. So ergibt sich ein Bild auf dem die Kanten verstärkt wurden, da in der addierten Maske bereits nur noch die Kanten und nicht mehr die unscharfen Bereiche vorhanden waren.